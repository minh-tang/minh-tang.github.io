[{"authors":["admin"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/minh-tang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/minh-tang/","section":"authors","summary":"","tags":null,"title":"Minh Tang","type":"authors"},{"authors":null,"categories":null,"content":"Course description The course provides an introduction to and overview of current research in random graph inference, with a particular focus on spectral methods and their applications to inference for independent-edge random graphs. Topics include concentration inequalities; analysis of matrix perturbations; spectral decompositions of graph adjacency and Laplacian matrices; consistent estimation of latent variables associated to vertices; clustering, community detection, and classification in networks; and multi-sample hypothesis testing for graphs. Emphasis will be on a framework for establishing classical properties\u0026mdash;consistency, normality, and efficiency\u0026mdash;for estimators of graph parameters. Students will read papers in the literature and are expected to participate actively in class.\nSyllabus and tentative schedule    Date Topics Readings     08/30 Introduction and overview    08/31 Random graphs models: Erdos-Renyi, stochastic blockmodels, preferential attachments  Bollobas et al., Hoff et al., Chung and Lu   09/05 Random dot product graphs, adjacency and Laplacian spectral embedding  Athreya et al.   09/07 Matrix concentration inequalities  Oliviera, Tropp, Lu and Peng   09/10 Matrix concentration inequalities (day 2)  Oliviera, Tropp, Lu and Peng   09/12 Matrix concentration inequalities (day 3)  Oliviera, Tropp, Lu and Peng   09/14 Subspace perturbation  Yu et al., Rohe et al.   09/17 Subspace perturbation (day 2)  Yu et al., Rohe et al.   09/19 Subspace perturbation (day 3)  Cai and Zhang   09/21 Clustering and spectral clustering  von Luxburg   09/24 Clustering and spectral clustering (day 2)  Belkin and Niyogi, Coifman and Lafon   09/26 Clustering and spectral clustering (day 3)  von Luxburg et al.   09/28 Estimation and consistency in stochastic blockmodel and random dot product graphs  Sussman et al., Sussman et al., Rohe et al.   10/01 Estimation and consistency in stochastic blockmodel and random dot product graphs (day 2)  Lyzinski et al.   10/03 Estimation and consistency in stochastic blockmodel and random dot product graphs (day 3)  Lyzinski et al., Cape et al.   10/05 A central limit theorem for scaled eigenvectors of random dot product graphs  Athreya et al.   10/08 Limit theorems for eigenvectors of the normalized Laplacian for random graphs  Tang and Priebe, Chernoff, Sarkar and Bickel   10/10 Limit theorems for eigenvectors of the normalized Laplacian for random graphs (day 2)  Tang and Priebe, Chernoff, Sarkar and Bickel   10/12 Limit theorems for eigenvectors of the normalized Laplacian for random graphs (day 3)  Tang and Priebe, Chernoff, Sarkar and Bickel   10/15 Asymptotically efficient estimators for stochastic blockmodels  Bickel et al., Tang et al.   10/17 Asymptotically efficient estimators for stochastic blockmodels (day 2)  Bickel et al., Tang et al.   10/19 Fall break  Candide, ou l\u0026rsquo;Optimisme   10/22 Asymptotically efficient estimators for stochastic blockmodels (day 3)  Bickel et al., Tang et al.   10/24 Two-sample semiparametric testing for random graphs  Tang et al.   10/26 Two-sample semiparametric testing for random graphs (day 2)  Tang et al.   10/29 Two-sample semiparametric testing for random graphs (day 3)  Levin et al.   10/31 Two-sample nonparametric testing for random graphs  Tang et al., Gretton et al.   11/02 Two-sample nonparametric testing for random graphs (day 2)  Tang et al., Gretton et al.   11/05 Universal singula value thresholding  Chatterjee, Xu   11/07 Universal singula value thresholding (day 2)  Chatterjee, Xu   11/09 Universal singula value thresholding (day 3)  Chatterjee, Xu   11/12 Breather day  The Corrs, Richie Havens   11/14 Exponential random graphs model  Shalizi and Rinaldo   11/16 Goodness-of-fit test in stochastic blockmodels  Lei, Wang and Bickel   11/26 Stochastic blockmodels and limit of detectability  Mossel et al., Abbe et al., Hajek et al., Abbe   11/28 Stochastic blockmodels and limit of detectability (day 2)  Mossel et al., Abbe et al., Hajek et al., Abbe   11/30 Stochastic blockmodels and limit of detectability (day 3)  Mossel et al., Abbe et al., Hajek et al., Abbe   12/03 All Caratheodory, all the time  Staying alive   12/05 Dynkin-Dynkin  Hey   12/07 Proof of the Riemann hypothesis using elementary linear algebra  Moskau    ","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"635cad4970b45f063ab2a72e8e109472","permalink":"/teaching/stat_graph/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/teaching/stat_graph/","section":"teaching","summary":"Course description The course provides an introduction to and overview of current research in random graph inference, with a particular focus on spectral methods and their applications to inference for independent-edge random graphs.","tags":null,"title":"Statistical inference on graphs","type":"teaching"},{"authors":["Xinjie Du","Minh Tang"],"categories":null,"content":"","date":1621869881,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621869881,"objectID":"b74107734796866de8d289116396ebff","permalink":"/publication/du_tang/","publishdate":"2021-05-24T11:24:41-04:00","relpermalink":"/publication/du_tang/","section":"publication","summary":"We consider the hypothesis testing problem that two vertices i and j of a generalized random dot product graph have the same latent positions, possibly up to scaling. Special cases of this hypotheses test include testing whether two vertices in a stochastic block model or degree-corrected stochastic block model graph have the same block membership vectors. We propose several test statistics based on the empirical Mahalanobis distances between the ith and jth rows of either the adjacency or the normalized Laplacian spectral embedding of the graph. We show that, under mild conditions, these test statistics have limiting chi-square distributions under both the null and local alternative hypothesis, and we derived explicit expressions for the non-centrality parameters under the local alternative. Using these limit results, we address the model selection problem of choosing between the standard stochastic block model and its degree-corrected variant. The effectiveness of our proposed tests are illustrated via both simulation studies and real data applications.","tags":[],"title":"Hypothesis testing for equality of latent positions in random graphs","type":"publication"},{"authors":["Avanti Athreya","Joshua Cape","Minh Tang"],"categories":null,"content":"","date":1620624505,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620624505,"objectID":"05829beac4a9f994e4d1619abab91cfc","permalink":"/publication/eigenval_sbm/","publishdate":"2021-05-10T01:28:25-04:00","relpermalink":"/publication/eigenval_sbm/","section":"publication","summary":"We derive the limiting distribution for the largest eigenvalues of the adjacency matrix for a stochastic blockmodel graph when the number of vertices tends to infinity. We show that, in the limit, these eigenvalues are jointly multivariate normal with bounded covariances. Our result extends the classic result of Furedi and Komlos on the fluctuation of the largest eigenvalue for Erdos-Renyi graphs.","tags":[],"title":"The eigenvalues of stochastic blockmodel graphs","type":"publication"},{"authors":["Joshua T. Vogelstein","Eric W. Bridgeford","Minh Tang","Da Zheng","Christopher Douville","Randall Burns","Mauro Maggioni"],"categories":null,"content":"","date":1619885926,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619885926,"objectID":"3afa4ed722f230cce418e4b0d80463f4","permalink":"/publication/lol/","publishdate":"2021-05-01T12:18:46-04:00","relpermalink":"/publication/lol/","section":"publication","summary":"To solve key biomedical problems, experimentalists now routinely measure millions or billions of features (dimensions) per sample, with the hope that data science techniques will be able to build accurate data-driven inferences. Because sample sizes are typically orders of magnitude smaller than the dimensionality of these data, valid inferences require finding a low-dimensional representation that preserves the discriminating information (e.g., whether the individual suffers from a particular disease). There is a lack of interpretable supervised dimensionality reduction methods that scale to millions of dimensions with strong statistical theoretical guarantees. We introduce an approach to extending principal components analysis by incorporating class-conditional moment estimates into the low-dimensional projection. The simplest version, Linear Optimal Low-rank projection, incorporates the class-conditional means. We prove, and substantiate with both synthetic and real data benchmarks, that Linear Optimal Low-Rank Projection and its generalizations lead to improved data representations for subsequent classification, while maintaining computational efficiency and scalability. Using multiple brain imaging datasets consisting of more than 150 million features, and several genomics datasets with more than 500,000 features, Linear Optimal Low-Rank Projection outperforms other scalable linear dimensionality reduction techniques in terms of accuracy, while only requiring a few minutes on a standard desktop computer.","tags":[],"title":"","type":"publication"},{"authors":["Avanti Athreya","Minh Tang","Youngser Park","Carey E. Priebe"],"categories":null,"content":"","date":1614491626,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614491626,"objectID":"a51b765ca97d39fc2a402cbb6f1f8ac6","permalink":"/publication/latent_structure_model/","publishdate":"2021-02-28T01:53:46-04:00","relpermalink":"/publication/latent_structure_model/","section":"publication","summary":"We define a latent structure model (LSM) random graph as a random dot product graph (RDPG) in which the latent position distribution incorporates both probabilistic and geometric constraints, delineated by a family of underlying distributions on some fixed Euclidean space, and a structural support submanifold from which the latent positions for the graph are drawn. For a one-dimensional latent structure model with known structural support, we show how spectral estimates of the latent positions of an RDPG can be used for efficient estimation of the paramaters of the LSM. We describe how to estimate or learn the structural support in cases where it is unknown, with an illustrative focus on graphs with latent positions along the Hardy-Weinberg curve. Finally, we use the latent structure model formulation to test bilateral homology in the *Drosophila* connectome.","tags":[],"title":"On estimation and inference in latent structure random graphs","type":"publication"},{"authors":["Yichi Zhang","Minh Tang"],"categories":null,"content":"","date":1610948968,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610948968,"objectID":"9a82c674587d0a4654cf29c79429dfc3","permalink":"/publication/node2vec/","publishdate":"2021-01-18T01:49:28-04:00","relpermalink":"/publication/node2vec/","section":"publication","summary":"Random-walk based network embedding algorithms like node2vec and DeepWalk are widely used to obtain Euclidean representation of the nodes in a network prior to performing down-stream network inference tasks. Nevertheless, despite their impressive empirical performance, there is a lack of theoretical results explaining their behavior. In this paper we studied the node2vec and DeepWalk algorithms through the perspective of matrix factorization. We analyze these algorithms in the setting of community detection for stochastic blockmodel graphs; in particular we established large-sample error bounds and prove consistent community recovery of node2vec/DeepWalk embedding followed by k-means clustering. Our theoretical results indicate a subtle interplay between the sparsity of the observed networks, the window sizes of the random walks, and the convergence rates of the node2vec/DeepWalk embedding toward the embedding of the true but unknown edge probabilities matrix. More specifically, as the network becomes sparser, our results suggest using larger window sizes, or equivalently, taking longer random walks, in order to attain better convergence rate for the resulting embeddings. The paper includes numerical experiments corroborating these observations.","tags":[],"title":"Consistency of random-walk based network embedding algorithms","type":"publication"},{"authors":["Joshua Agteberg","Minh Tang","Carey E. Priebe"],"categories":null,"content":"","date":1608443368,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608443368,"objectID":"b2d9cffd7ecabbf4f17bce2f230fe4f2","permalink":"/publication/nonpar2/","publishdate":"2020-12-20T01:49:28-04:00","relpermalink":"/publication/nonpar2/","section":"publication","summary":"We propose a nonparametric two-sample test statistic for low-rank, conditionally independent edge random graphs whose edge probability matrices have negative eigenvalues and arbitrarily close eigenvalues. Our proposed test statistic involves using the maximum mean discrepancy applied to suitably rotated rows of a graph embedding, where the rotation is estimated using optimal transport. We show that our test statistic, appropriately scaled, is consistent for sufficiently dense graphs, and we study its convergence under different sparsity regimes. In addition, we provide empirical evidence suggesting that our novel alignment procedure can perform better than the naïve alignment in practice, where the naïve alignment assumes an eigengap.","tags":[],"title":"Nonparametric Two-Sample Hypothesis Testing for Random Graphs with Negative and Repeated Eigenvalues","type":"publication"},{"authors":["Runbing Zheng","Vince Lyznsiki","Carey E. Priebe","Minh Tang"],"categories":null,"content":"","date":1603259368,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603259368,"objectID":"3ee03a6bb817cf9451649a8f0009787c","permalink":"/publication/vn_zheng/","publishdate":"2020-10-21T01:49:28-04:00","relpermalink":"/publication/vn_zheng/","section":"publication","summary":"Given a network and a subset of interesting vertices whose identities are only partially known, the vertex nomination problem seeks to rank the remaining vertices in such a way that the interesting vertices are ranked at the top of the list. An important variant of this problem is vertex nomination in the multi-graphs setting. Given two graphs G1, G2, with common vertices and a vertex of interest x in G1, we wish to rank the vertices of G2$ such that the vertices most similar to x are ranked at the top of the list. The current paper addresses this problem and proposes a method that first applies adjacency spectral graph embedding to embed the graphs into a common Euclidean space, and then solves a penalized linear assignment problem to obtain the nomination lists. Since the spectral embedding of the graphs are only unique up to orthogonal transformations, we present two approaches to eliminate this potential non-identifiability. One approach is based on orthogonal Procrustes and is applicable when there are enough vertices with known correspondence between the two graphs. Another approach uses adaptive point set registration and is applicable when there are few or no vertices with known correspondence. We show that our nomination scheme leads to accurate nomination under a generative model for pairs of random graphs that are approximately low-rank and possibly with pairwise edge correlations. We illustrate our algorithm's performance through simulation studies on synthetic data as well as analysis of a high-school friendship network and analysis of transition rates between web pages on the Bing search engine.","tags":[],"title":"Vertex nomination between graphs via spectral embedding and quadratic programming","type":"publication"},{"authors":["Yiran Wang","Minh Tang","Soumendra N. Lahiri"],"categories":null,"content":"","date":1596455077,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596455077,"objectID":"d9297851d6746094e9833a22ec11d50e","permalink":"/publication/spearman/","publishdate":"2020-08-03T07:44:37-04:00","relpermalink":"/publication/spearman/","section":"publication","summary":"We propose a valid and consistent test for the hypothesis that two latent distance random graphs on the same vertex set have the same generating latent positions, up to some unidentifiable similarity transformations. Our test statistic is based on first estimating the edge probabilities matrices by truncating the singular value decompositions of the averaged adjacency matrices in each population and then computing a Spearman rank correlation coefficient between these estimates. Experimental results on simulated data indicate that the test procedure has power even when there is only one sample from each population, provided that the number of vertices is not too small. Application on a dataset of neural connectome graphs showed that we can distinguish between scans from different age groups while application on a dataset of epileptogenic recordings showed that we can discriminate between seizure and non-seizure events","tags":[],"title":"Two-sample testing on latent distance graphs with unknown link functions","type":"publication"},{"authors":["Keith Levin","Fred Roosta","Minh Tang","Michael W. Mahoney","Carey E. Priebe"],"categories":null,"content":"","date":1593529221,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593529221,"objectID":"754ec370f178994f51ef4d167f958065","permalink":"/publication/lseoos/","publishdate":"2020-06-30T11:00:21-04:00","relpermalink":"/publication/lseoos/","section":"publication","summary":"Performing statistical inference on collections of graphs is of import to many disciplines. Graph embedding, in which the vertices of a graph are mapped to vectors in a low-dimensional Euclidean space, has gained traction as a basic tool for graph analysis. In this paper, we describe an omnibus embedding in which multiple graphs on the same vertex set are jointly embedded into a single space with a distinct representation for each graph. We prove a central limit theorem for this omnibus embedding, and we show that this simultaneous embedding into a common space allows comparison of graphs without the need to perform pairwise alignments of graph embeddings. Experimental results demonstrate that the omnibus embedding improves upon existing methods, allowing better power in multiple-graph hypothesis testing and yielding better estimation in a latent position model.","tags":[],"title":"Limit theorems for out-of-sample extensions of the adjacency and Laplacian spectral embeddings","type":"publication"},{"authors":["Gongkai Li","Minh Tang","Nicholas Charon","Carey E. Priebe"],"categories":null,"content":"","date":1593444281,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593444281,"objectID":"bedd4af0bf472e0bd2a813f8d3b5e7d6","permalink":"/publication/cmds_clt/","publishdate":"2020-06-29T11:24:41-04:00","relpermalink":"/publication/cmds_clt/","section":"publication","summary":"Classical multidimensional scaling (CMDS) is a widely used method in manifold learning. It takes in a dissimilarity matrix and outputs a coordinate matrix based on a spectral decomposition. However, there are not yet any statistical results characterizing the performance ofCMDS under randomness, such as perturbation analysis when the objects are sampled from a probabilistic model. In this paper, we present such an analysis given that the objects are sampled from a suitable distribution. In particular, we show that the resulting embedding gives rise to a central limit theorem for noisy dissimilarity measurements, and provide compelling simulation and real data illustration of this CLT for CMDS.","tags":[],"title":"A central limit theorem for classical multidimensional scaling","type":"publication"},{"authors":["Michael W. Trosset","Mingyue Gao","Minh Tang","Carey E. Priebe"],"categories":null,"content":"","date":1586929768,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586929768,"objectID":"a4eb166e709f466d90bd7f30e9dd6116","permalink":"/publication/isomap/","publishdate":"2020-04-15T01:49:28-04:00","relpermalink":"/publication/isomap/","section":"publication","summary":"A generalisation of a latent position network model known as the random dot product graph model is considered. The resulting model may be of independent interest because it has the unique property of representing a mixture of connectivity behaviours as the corresponding convex combination in latent space. We show that, whether the normalised Laplacian or adjacency matrix is used, the vector representations of nodes obtained by spectral embedding provide strongly consistent latent position estimates with asymptotically Gaussian error. Direct methodological consequences follow from the observation that the well-known mixed membership and standard stochastic block models are special cases where the latent positions live respectively inside or on the vertices of a simplex. Estimation via spectral embedding can therefore be achieved by respectively estimating this simplicial support, or fitting a Gaussian mixture model. In the latter case, the use of $K$-means, as has been previously recommended, is suboptimal and for identifiability reasons unsound. Empirical improvements in link prediction, as well as the potential to uncover much richer latent structure (than available under the mixed membership or standard stochastic block models) are demonstrated in a cyber-security example.","tags":[],"title":"Learning 1-dimensional submanifolds for subsequent inference on random dot product graphs","type":"publication"},{"authors":["Joshua Agteberg","Minh Tang","Carey E. Priebe"],"categories":null,"content":"","date":1585633768,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585633768,"objectID":"e7ef104fa569d7c6b768bc27e2bc38ec","permalink":"/publication/non_identifiability/","publishdate":"2020-03-31T01:49:28-04:00","relpermalink":"/publication/non_identifiability/","section":"publication","summary":"A generalisation of a latent position network model known as the random dot product graph model is considered. The resulting model may be of independent interest because it has the unique property of representing a mixture of connectivity behaviours as the corresponding convex combination in latent space. We show that, whether the normalised Laplacian or adjacency matrix is used, the vector representations of nodes obtained by spectral embedding provide strongly consistent latent position estimates with asymptotically Gaussian error. Direct methodological consequences follow from the observation that the well-known mixed membership and standard stochastic block models are special cases where the latent positions live respectively inside or on the vertices of a simplex. Estimation via spectral embedding can therefore be achieved by respectively estimating this simplicial support, or fitting a Gaussian mixture model. In the latter case, the use of $K$-means, as has been previously recommended, is suboptimal and for identifiability reasons unsound. Empirical improvements in link prediction, as well as the potential to uncover much richer latent structure (than available under the mixed membership or standard stochastic block models) are demonstrated in a cyber-security example.","tags":[],"title":"On two distinct sources of non-identifiability in latent position random graph models","type":"publication"},{"authors":["Joshua Cape","Minh Tang","Carey E. Priebe"],"categories":null,"content":"","date":1567338277,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567338277,"objectID":"085b90b6c5ceae472789b684820cff18","permalink":"/publication/elucidation/","publishdate":"2019-09-01T07:44:37-04:00","relpermalink":"/publication/elucidation/","section":"publication","summary":"Statistical inference on graphs often proceeds via spectral methods involving low-dimensional embeddings of matrix-valued graph representations, such as the graph Laplacian or adjacency matrix. In this paper, we analyze the asymptotic information-theoretic relative performance of Laplacian spectral embedding and adjacency spectral embedding for block assignment recovery in stochastic block model graphs by way of Chernoff information. We investigate the relationship between spectral embedding performance and underlying network structure (e.g. homogeneity, affinity, core-periphery, (un)balancedness) via a comprehensive treatment of the two-block stochastic block model and the class of K-block models exhibiting homogeneous balanced affinity structure. Our findings support the claim that, for a particular notion of sparsity, loosely speaking, 'Laplacian spectral embedding favors relatively sparse graphs, whereas adjacency spectral embedding favors not-too-sparse graphs.' We also provide evidence in support of the claim that 'adjacency spectral embedding favors core-periphery network structure.'","tags":[],"title":"On spectral embedding performance and elucidating network structure","type":"publication"},{"authors":["Joshua Cape","Minh Tang","Carey E. Priebe"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"f879b1872eab4870c10c97fd6cf7de93","permalink":"/publication/2toinfty_biometrika/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/publication/2toinfty_biometrika/","section":"publication","summary":"Estimating eigenvectors and low-dimensional subspaces is of central importance for numerous problems in statistics, computer science and applied mathematics. In this paper we characterize the behaviour of perturbed eigenvectors for a range of signal-plus-noise matrix models encountered in statistical and random-matrix-theoretic settings. We establish both first-order approximation results, i.e., sharp deviations, and second-order distributional limit theory, i.e., fluctuations. The concise methodology presented in this paper synthesizes tools rooted in two core concepts, namely deterministic decompositions of matrix perturbations and probabilistic matrix concentration phenomena. We illustrate our theoretical results with simulation examples involving stochastic block model random graphs.","tags":[],"title":"Signal-plus-noise matrix models: eigenvector deviations and fluctuations","type":"publication"},{"authors":["Joshua Cape","Minh Tang","Carey E. Priebe"],"categories":null,"content":"Paper accepted July 2018.\n","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"e61b825142d0ff662137628d7af82b2b","permalink":"/publication/2_to_infty/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/2_to_infty/","section":"publication","summary":"The singular value matrix decomposition plays a ubiquitous role throughout statistics and related fields. Myriad applications including clustering, classification, and dimensionality reduction involve studying and exploiting the geometric structure of singular values and singular vectors. This paper contributes to the literature by providing a novel collection of technical and theoretical tools for studying the geometry of singular subspaces using the $2\\to\\infty$ norm. Motivated by preliminary deterministic Procrustes analysis, we consider a general matrix perturbation setting in which we derive a new Procrustean matrix decomposition. Together with flexible machinery developed for the $2\\to\\infty$ norm, this allows us to conduct a refined analysis of the induced perturbation geometry with respect to the underlying singular vectors even in the presence of singular value multiplicity. Our analysis yields perturbation bounds for a range of popular matrix noise models, each of which has a meaningful associated statistical inference task. We discuss how the $2\\to\\infty$ norm is arguably the preferred norm in certain statistical settings. Specific applications discussed in this paper include the problem of covariance matrix estimation, singular subspace recovery, and multiple graph inference.  Both our novel Procrustean matrix decomposition and the technical machinery developed for the $2\\to\\infty$ norm may be of independent interest.","tags":[],"title":"The two-to-infinity norm and singular subspace geometry with applications to high-dimensional statistics","type":"publication"},{"authors":["Carey E. Priebe","Youngser Park","Joshua T. Vogelstein","John M. Conroy","Vince Lyzinski","Minh Tang","Avanti Athreya","Joshua Cape","Eric Bridgeford"],"categories":null,"content":"","date":1552045477,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552045477,"objectID":"d7664adf9a34acd08ff09eab5352b851","permalink":"/publication/twotruths/","publishdate":"2019-03-08T07:44:37-04:00","relpermalink":"/publication/twotruths/","section":"publication","summary":"Clustering is concerned with coherently grouping observations without any explicit concept of true groupings. Spectral graph clustering - clustering the vertices of a graph based on their spectral embedding - is commonly approached via K-means (or, more generally, Gaussian mixture model) clustering composed with either Laplacian or Adjacency spectral embedding (LSE or ASE). Recent theoretical results provide new understanding of the problem and solutions, and lead us to a 'Two Truths' LSE vs. ASE spectral graph clustering phenomenon convincingly illustrated here via a diffusion MRI connectome data set: the different embedding methods yield different clustering results, with LSE capturing left hemisphere/right hemisphere affinity structure and ASE capturing gray matter/white matter core-periphery structure.","tags":[],"title":"On a 'two truths' phenomenon in spectral graph clustering","type":"publication"},{"authors":["Minh Tang","Carey E. Priebe"],"categories":null,"content":"","date":1534464000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534464000,"objectID":"527df5780ad7b40617117d4858b4edc1","permalink":"/publication/lseclt/","publishdate":"2018-08-17T00:00:00Z","relpermalink":"/publication/lseclt/","section":"publication","summary":"We prove a central limit theorem for the components of the eigenvectors corresponding to the $d$ largest eigenvalues of the normalized Laplacian matrix of a finite dimensional random dot product graph. As a corollary, we show that for stochastic blockmodel graphs, the rows of the spectral embedding of the normalized Laplacian converge to multivariate normals and furthermore the mean and the covariance matrix of each row are functions of the associated vertex's block membership. Together with prior results for the eigenvectors of the adjacency matrix, we then compare, via the Chernoff information between multivariate normal distributions, how the choice of embedding method impacts subsequent inference. We demonstrate that neither embedding method dominates with respect to the inference task of recovering the latent block assignments.","tags":[],"title":"Limit theorems for eigenvectors of the normalized Laplacian for random graphs","type":"publication"},{"authors":["Patrick Rubin-Delanchy","Carey E. Priebe","Minh Tang","Joshua Cape"],"categories":null,"content":"","date":1532843368,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532843368,"objectID":"7b37204b5fd03a25627e2a947b90a53b","permalink":"/publication/grdpg/","publishdate":"2018-07-29T01:49:28-04:00","relpermalink":"/publication/grdpg/","section":"publication","summary":"A generalisation of a latent position network model known as the random dot product graph model is considered. The resulting model may be of independent interest because it has the unique property of representing a mixture of connectivity behaviours as the corresponding convex combination in latent space. We show that, whether the normalised Laplacian or adjacency matrix is used, the vector representations of nodes obtained by spectral embedding provide strongly consistent latent position estimates with asymptotically Gaussian error. Direct methodological consequences follow from the observation that the well-known mixed membership and standard stochastic block models are special cases where the latent positions live respectively inside or on the vertices of a simplex. Estimation via spectral embedding can therefore be achieved by respectively estimating this simplicial support, or fitting a Gaussian mixture model. In the latter case, the use of $K$-means, as has been previously recommended, is suboptimal and for identifiability reasons unsound. Empirical improvements in link prediction, as well as the potential to uncover much richer latent structure (than available under the mixed membership or standard stochastic block models) are demonstrated in a cyber-security example.","tags":[],"title":"A statistical interpretation of spectral embedding: the generalised random dot product graph","type":"publication"},{"authors":["Avanti Athreya","Donniell E. Fishkind","Keith Levin","Vince Lyzinski","Youngser Park","Yichen Qin","Daniel L. Sussman","Minh Tang","Joshua T. Vogelstein","Carey E. Priebe"],"categories":null,"content":"","date":1530424594,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530424594,"objectID":"7fca629d28d7b8957a2189212461f84a","permalink":"/publication/rdpg_jmlr/","publishdate":"2018-07-01T01:56:34-04:00","relpermalink":"/publication/rdpg_jmlr/","section":"publication","summary":"The random dot product graph (RDPG) is an independent-edge random graph that is analytically tractable and, simultaneously, either encompasses or can successfully approximate a wide range of random graphs, from relatively simple stochastic block models to complex latent position graphs. In this survey paper, we describe a comprehensive paradigm for statistical inference on random dot product graphs, a paradigm centered on spectral embeddings of adjacency and Laplacian matrices. We examine the analogues, in graph inference, of several canonical tenets of classical Euclidean inference: in particular, we summarize a body of existing results on the consistency and asymptotic normality of the adjacency and Laplacian spectral embeddings, and the role these spectral embeddings can play in the construction of single- and multi-sample hypothesis tests for graph data. We investigate several real-world applications, including community detection and classification in large social networks and the determination of functional and biologically relevant network properties from an exploratory data analysis of the *Drosophila* connectome. We outline requisite background and current open problems in spectral graph inference.","tags":[],"title":"Statistical inference on random dot product graphs: a survey","type":"publication"},{"authors":["Minh Tang","Joshua Cape","Carey E. Priebe"],"categories":null,"content":"","date":1509340708,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509340708,"objectID":"ca7127607c0fb0e60df10e5092ed0540","permalink":"/publication/ase_efficiency/","publishdate":"2017-10-30T01:18:28-04:00","relpermalink":"/publication/ase_efficiency/","section":"publication","summary":"We establish asymptotic normality results for estimation of the block probability matrix $\\mathbf{B}$ in stochastic blockmodel graphs using spectral embedding when the average degrees grows at the rate of $\\omega(\\sqrt{n})$ in $n$, the number of vertices. As a corollary, we show that when $\\mathbf{B}$ is of full-rank, estimates of $\\mathbf{B}$ obtained from spectral embedding are asymptotically efficient. When $\\mathbf{B}$ is singular the estimates obtained from spectral embedding can have smaller mean square error than those obtained from maximizing the log-likelihood under no rank assumption, and furthermore, can be almost as efficient as the true MLE that assume known $\\mathrm{rk}(\\mathbf{B})$. Our results indicate, in the context of stochastic blockmodel graphs, that spectral embedding is not just computationally tractable, but that the resulting estimates are also admissible, even when compared to the purportedly optimal but computationally intractable maximum likelihood estimation under no rank assumption.","tags":[],"title":"Asymptotically efficient estimators for stochastic blockmodels: the naive MLE, the rank-constrained MLE, and the spectral","type":"publication"},{"authors":["Keith Levin","Avanti Athreya","Minh Tang","Vince Lyzinski","Carey E. Priebe"],"categories":null,"content":"","date":1506783621,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506783621,"objectID":"854c21431242137a3dc9f9bda0ac8065","permalink":"/publication/omni/","publishdate":"2017-09-30T11:00:21-04:00","relpermalink":"/publication/omni/","section":"publication","summary":"Performing statistical inference on collections of graphs is of import to many disciplines. Graph embedding, in which the vertices of a graph are mapped to vectors in a low-dimensional Euclidean space, has gained traction as a basic tool for graph analysis. In this paper, we describe an omnibus embedding in which multiple graphs on the same vertex set are jointly embedded into a single space with a distinct representation for each graph. We prove a central limit theorem for this omnibus embedding, and we show that this simultaneous embedding into a common space allows comparison of graphs without the need to perform pairwise alignments of graph embeddings. Experimental results demonstrate that the omnibus embedding improves upon existing methods, allowing better power in multiple-graph hypothesis testing and yielding better estimation in a latent position model.","tags":[],"title":"A central limit theorem for an omnibus embedding of random dot product graphs","type":"publication"},{"authors":["Joshua Cape","Minh Tang","Carey E. Priebe"],"categories":null,"content":"","date":1504159373,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504159373,"objectID":"ed95508b867c8befe7d9e3037c556360","permalink":"/publication/kato_temple/","publishdate":"2017-08-31T02:02:53-04:00","relpermalink":"/publication/kato_temple/","section":"publication","summary":"We present an adaptation of the Kato-Temple inequality for bounding perturbations of eigenvalues with applications to statistical inference for random graphs, specifically hypothesis testing and change-point detection. We obtain explicit high-probability bounds for the individual distances between certain signal eigenvalues of a graph's adjacency matrix and the corresponding eigenvalues of the model's edge probability matrix, even when the latter eigenvalues have multiplicity. Our results extend more broadly to the perturbation of singular values in the presence of quite general random matrix noise.","tags":[],"title":"The Kato-Temple inequality and eigenvalue concentration with applications to graph inference","type":"publication"},{"authors":["Minh Tang","Avanti Athreya","Daniel L. Sussman","Vince Lyzinski","Carey E. Priebe"],"categories":null,"content":"","date":1501564419,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501564419,"objectID":"afc9a235387010dacdbeb7e1b51b211b","permalink":"/publication/nonpar/","publishdate":"2017-08-01T01:13:39-04:00","relpermalink":"/publication/nonpar/","section":"publication","summary":"We consider the problem of testing whether two finite-dimensional random dot product graphs have generating latent positions that are independently drawn from the same distribution, or distributions that are related via scaling or projection. We propose a test statistic that is a kernel-based function of the adjacency spectral embedding for each graph. We obtain a limiting distribution for our test statistic under the null and we show that our test procedure is consistent across a broad range of alternatives.","tags":[],"title":"A nonparametric two-sample hypothesis testing problem for random dot product graphs","type":"publication"},{"authors":["Runze Tang","Minh Tang","Joshua T. Vogelstein","Carey E. Priebe"],"categories":null,"content":"","date":1501514505,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501514505,"objectID":"2af21b0e899afdeff9ee0a7b83eb4d3b","permalink":"/publication/robust_llg/","publishdate":"2017-07-31T11:21:45-04:00","relpermalink":"/publication/robust_llg/","section":"publication","summary":"Estimation of graph parameters based on a collection of graphs is essential for a wide range of graph inference tasks. In practice, weighted graphs are generally observed with edge contamination. We consider a weighted latent position graph model contaminated via an edge weight gross error model and propose an estimation methodology based on robust $\\mathrm{L}_q$ estimation followed by low-rank adjacency spectral decomposition. We demonstrate that, under appropriate conditions, our estimator both maintains $\\mathrm{L}_q$ robustness and wins the bias-variance tradeoff by exploiting low-rank graph structure. We illustrate the improvement offered by our estimator via both simulations and a human connectome data experiment.","tags":[],"title":"Robust estimation from multiple graphs under gross error contamination","type":"publication"},{"authors":["Minh Tang","Avanti Athreya","Daniel L. Sussman","Vince Lyzinski","Youngser Park","Carey E. Priebe"],"categories":null,"content":"","date":1491714294,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491714294,"objectID":"69e28b114e651c48a154b0c87164be31","permalink":"/publication/semipar/","publishdate":"2017-04-09T01:04:54-04:00","relpermalink":"/publication/semipar/","section":"publication","summary":"Two-sample hypothesis testing for random graphs arises naturally in neuroscience, social networks, and machine learning. In this paper, we consider a semiparametric problem of two-sample hypothesis testing for a class of latent position random graphs. We formulate a notion of consistency in this context and propose a valid test for the hypothesis that two finite-dimensional random dot product graphs on a common vertex set have the same generating latent positions or have generating latent positions that are scaled or diagonal transformations of one another. Our test statistic is a function of a spectral decomposition of the adjacency matrix for each graph and our test procedure is consistent across a broad range of alternatives. We apply our test procedure to real biological data: in a test-retest data set of neural connectome graphs, we are able to distinguish between scans from different subjects; and in the *C.elegans* connectome, we are able to distinguish between chemical and electrical networks. The latter example is a concrete demonstration that our test can have power even for small sample sizes. We conclude by discussing the relationship between our test procedure and generalized likelihood ratio tests.","tags":[],"title":"A semiparametric two-sample hypothesis testing problem for random dot product graphs","type":"publication"},{"authors":["Vince Lyzinski","Minh Tang","Avanti Athreya","Youngser Park","Carey E. Priebe"],"categories":null,"content":"","date":1490940379,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1490940379,"objectID":"7be29c634584cd4b7b988b6baca17748","permalink":"/publication/hsbm_tnse/","publishdate":"2017-03-31T02:06:19-04:00","relpermalink":"/publication/hsbm_tnse/","section":"publication","summary":"We propose a robust, scalable, integrated methodology for community detection and community comparison in graphs. In our procedure, we first embed a graph into an appropriate Euclidean space to obtain a low-dimensional representation, and then cluster the vertices into communities. We next employ nonparametric graph inference techniques to identify structural similarity among these communities. These two steps are then applied recursively on the communities, allowing us to detect more fine-grained structure. We describe a hierarchical stochastic blockmodel---namely, a stochastic blockmodel with a natural hierarchical structure---and establish conditions under which our algorithm yields consistent estimates of model parameters and motifs, which we define to be stochastically similar groups of subgraphs. Finally, we demonstrate the effectiveness of our algorithm in both simulated and real data. Specifically, we address the problem of locating similar subcommunities in a partially reconstructed Drosophila connectome and in the social network Friendster.","tags":[],"title":"Community detection and classification in hierarchical stochastic blockmodels","type":"publication"},{"authors":["Shakira Suwan","Dominic S. Lee","Runze Tang","Daniel L. Sussman","Minh Tang","Carey E. Priebe"],"categories":null,"content":"","date":1464789180,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1464789180,"objectID":"92feced3a841503fe7c98412379653cf","permalink":"/publication/sbm_ejs/","publishdate":"2016-06-01T09:53:00-04:00","relpermalink":"/publication/sbm_ejs/","section":"publication","summary":"Inference for the stochastic blockmodel is currently of burgeoning interest in the statistical community, as well as in various application domains as diverse as social networks, citation networks, brain connectivity networks (connectomics), etc. Recent theoretical developments have shown that spectral embedding of graphs yields tractable distributional results; in particular, a random dot product latent position graph formulation of the stochastic blockmodel informs a mixture of normal distributions for the adjacency spectral embedding. We employ this new theory to provide an empirical Bayes methodology for estimation of block memberships of vertices in a random graph drawn from the stochastic blockmodel, and demonstrate its practical utility. The posterior inference is conducted using a Metropolis-within-Gibbs algorithm. The theory and methods are illustrated through Monte Carlo simulation studies, both within the stochastic blockmodel and beyond, and experimental results on a Wikipedia data set are presented.","tags":[],"title":"Empirical Bayes estimation for the stochastic blockmodels","type":"publication"},{"authors":["Avanti Athreya","Carey E. Priebe","Minh Tang","Vince Lyzinski","David J. Marchette","Daniel L. Sussman"],"categories":null,"content":"","date":1454254144,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1454254144,"objectID":"5d15d06f057b3eb2fe624145aec62037","permalink":"/publication/ase_clt/","publishdate":"2016-01-31T11:29:04-04:00","relpermalink":"/publication/ase_clt/","section":"publication","summary":"We prove a central limit theorem for the components of the largest eigenvectors of the adjacency matrix of a finite-dimensional random dot product graph whose true latent positions are unknown. We use the spectral embedding of the adjacency matrix to construct consistent estimates for the latent positions, and we show that the appropriately scaled differences between the estimated and true latent positions converge to a mixture of Gaussian random variables. We state several corollaries, including an alternate proof of a central limit theorem for the first eigenvector of the adjacency matrix of an Erdos-Rényi random graph.","tags":[],"title":"A limit theorem for scaled eigenvectors of random dot product graphs","type":"publication"},{"authors":["Carey E. Priebe","Daniel L. Sussman","Minh Tang","Joshua T. Vogelstein"],"categories":null,"content":"","date":1451575991,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451575991,"objectID":"784a666251ab55238f1448eb73784967","permalink":"/publication/errorful_jcgs/","publishdate":"2015-12-31T11:33:11-04:00","relpermalink":"/publication/errorful_jcgs/","section":"publication","summary":"Statistical inference on graphs is a burgeoning field in the applied and theoretical statistics communities, as well as throughout the wider world of science, engineering, business, etc. In many applications, we are faced with the reality of errorfully observed graphs. That is, the existence of an edge between two vertices is based on some imperfect assessment. In this paper, we consider a graph $G=(V,E)$. We wish to perform an inference task---the inference task considered here is \"vertex classification\". However, we do not observe $G$; rather, for each potential edge $uv \\in \\tbinom{V}{2}$ we observe an \"edge-feature\" which we use to classify $uv$ as edge/not-edge. Thus we errorfully observe $G$ when we observe the graph $\\tilde{G}=(V,\\tilde{E})$ as the edges in $\\tilde{E}$ arise from the classifications of the \"edge-features\", and are expected to be errorful. Moreover, we face a quantity/quality trade-off regarding the edge-features we observe --- more informative edge-features are more expensive, and hence the number of potential edges that can be assessed decreases with the quality of the edge-features. We studied this problem by formulating a quantity/quality tradeoff for a simple class of random graphs model, namely the stochastic blockmodel. We then consider a simple but optimal vertex classifier for classifying $v$ and we derive the optimal quantity/quality operating point for subsequent graph inference in the face of this trade-off. The optimal operating points for the quantity/quality trade-off are surprising and illustrate the issue that methods for intermediate tasks should be chosen to maximize performance for the ultimate inference task. Finally, we investigate the quantity/quality tradeoff for errorful obesrvations of the *C.elegans* connectome graph.","tags":[],"title":"Statistical inference on errorfully observed graphs","type":"publication"},{"authors":["Cencheng Shen","Ming Sun","Minh Tang","Carey E. Priebe"],"categories":null,"content":"","date":1409586723,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409586723,"objectID":"c483d8273f2e5b604e81a473ee21a14c","permalink":"/publication/gcca_jmva/","publishdate":"2014-09-01T11:52:03-04:00","relpermalink":"/publication/gcca_jmva/","section":"publication","summary":"For multiple multivariate datasets, we derive conditions under which Generalized Canon- ical Correlation Analysis improves classification performance of the projected datasets, compared to standard Canonical Correlation Analysis using only two data sets. We illus- trate our theoretical results with simulations and a real data experiment.","tags":[],"title":"Generalized canonical correlation analysis for classification","type":"publication"},{"authors":["Vince Lyzinski","Daniel L. Sussman","Minh Tang","Avanti Athreya","Carey E. Priebe"],"categories":null,"content":"","date":1409586413,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409586413,"objectID":"1c8f86e682ac24c08671e608c010a168","permalink":"/publication/perfect_ejs/","publishdate":"2014-09-01T11:46:53-04:00","relpermalink":"/publication/perfect_ejs/","section":"publication","summary":"Vertex clustering in a stochastic blockmodel graph has wide applicability and has been the subject of extensive research. In thispaper, we provide a short proof that the adjacency spectral embedding can be used to obtain perfect clustering for the stochastic blockmodel and the degree-corrected stochastic blockmodel. We also show an analogous result for the more general random dot product graph model.","tags":[],"title":"Perfect clustering for stochastic blockmodel graphs via adjacency spectral embedding","type":"publication"},{"authors":["Heng Wang","Minh Tang","Youngser Park","Carey E. Priebe"],"categories":null,"content":"","date":1391270306,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391270306,"objectID":"911e08af9092bf7a6f4cbea3e182d323","permalink":"/publication/locality_tsp/","publishdate":"2014-02-01T11:58:26-04:00","relpermalink":"/publication/locality_tsp/","section":"publication","summary":"The ability to detect change-points in a dynamic network or a time series of graphs is an increasingly important task in many applications of the emerging discipline of graph signal processing. This paper formulates change-point detection as a hypothesis testing problem in terms of a generative latent position model, focusing on the special case of the Stochastic Block Model time series. We analyze two classes of scan statistics, based on distinct underlying locality statistics presented in the literature. Our main contribution is the derivation of the limiting distributions and power characteristics of the competing scan statistics. Performance is compared theoretically, on synthetic data, and on the Enron email corpus. We demonstrate that both statistics are admissible in one simple setting, while one of the statistics is inadmissible a second setting.","tags":[],"title":"Locality statistics for anomaly detection in time series of graphs","type":"publication"},{"authors":["Daniel L. Sussman","Minh Tang","Carey E. Priebe"],"categories":null,"content":"","date":1391184148,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391184148,"objectID":"45bdb01d349b12c3d99ad08f2c08b6fb","permalink":"/publication/tsp_tpami/","publishdate":"2014-01-31T12:02:28-04:00","relpermalink":"/publication/tsp_tpami/","section":"publication","summary":"In this work, we show that using the eigen-decomposition of the adjacency matrix, we can consistently estimate latent positions for random dot product graphs provided the latent positions are i.i.d. from some distribution. If class labels are observed for a number of vertices tending to infinity, then we show that the remaining vertices can be classified with error converging to Bayes optimal using the $k$-nearest-neighbors classification rule. We evaluate the proposed methods on simulated data and a graph derived from Wikipedia.","tags":[],"title":"Consistent latent position estimation and vertex classification for random dot product graphs","type":"publication"},{"authors":["Nam H. Lee","Jordan Yoder","Minh Tang","Carey E. Priebe"],"categories":null,"content":"","date":1375286911,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1375286911,"objectID":"58b24c500792eef3e1d06dcd35946113","permalink":"/publication/multiscale/","publishdate":"2013-07-31T12:08:31-04:00","relpermalink":"/publication/multiscale/","section":"publication","summary":"We model messaging activities as a hierarchical doubly stochastic point process with three main levels and develop an iterative algorithm for inferring actors’ relative latent positions from a stream of messaging activity data. Each of the message-exchanging actors is modeled as a process in a latent space. The actors’ latent positions are assumed to be influenced by the distribution of a much larger population over the latent space. Each actor’s movement in the latent space is modeled as being governed by two parameters that we call confidence and visibility, in addition to dependence on the population distribution. The messaging frequency between a pair of actors is assumed to be inversely proportional to the distance between their latent positions. Our inference algorithm is based on a projection approach to an online filtering problem. The algorithm associates each actor with a probability density-valued process, and each probability density is assumed to be a mixture of basis functions. For efficient numerical experiments, we further develop our algorithm for the case where the basis functions are obtained by translating and scaling a standard Gaussian density.","tags":[],"title":" On latent position inference from doubly stochastic messaging activities","type":"publication"},{"authors":["Minh Tang","Daniel L. Sussman","Carey E. Priebe"],"categories":null,"content":"","date":1372651200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372651200,"objectID":"10dd5288dbc2e63406236b07c7ad6518","permalink":"/publication/tsp_aos/","publishdate":"2013-07-01T00:00:00-04:00","relpermalink":"/publication/tsp_aos/","section":"publication","summary":"In this work we show that, using the eigen-decomposition of the adjacency matrix, we can consistently estimate feature maps for latent position graphs with positive definite link function $\\kappa$, provided that the latent positions are i.i.d. from some distribution $F$. We then consider the exploitation task of vertex classification where the link function $\\kappa$ belongs to the class of universal kernels and class labels are observed for a number of vertices tending to infinity and that the remaining vertices are to be classified. We show that minimization of the empirical $\\varphi$-risk for some convex surrogate $\\varphi$ of $0$–$1$ loss over a class of linear classifiers with increasing complexities yields a universally consistent classifier, that is, a classification rule with error converging to Bayes optimal for any distribution $F$.","tags":[],"title":"Universally consistent vertex classification for latent position graphs","type":"publication"},{"authors":["Minh Tang","Nam H. Lee","Youngser Park","Carey E. Priebe"],"categories":null,"content":"","date":1364832901,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1364832901,"objectID":"65cd6bdce5d4292c1cb8f40b84332a6a","permalink":"/publication/tlpp_tsp/","publishdate":"2013-04-01T12:15:01-04:00","relpermalink":"/publication/tlpp_tsp/","section":"publication","summary":"Hypothesis testing on time series of attributed graphs has applications in diverse areas, e.g., social network analysis (wherein vertices represent individual actors or organizations), connectome inference (wherein vertices are neurons or brain regions) and text processing (wherein vertices represent authors or documents). We consider the problem of anomaly/change point detection given the latent process model for time series of graphs with categorical attributes on the edges. Various attributed graph invariants are considered, and their power for detection as a function of a linear fusion parameter is presented. Our main result is that inferential performance in mathematically tractable first-order and second-order approximation models does provide guidance for methodological choices applicable to the exact (realistic but intractable) model. Furthermore, to the extent that the exact model is realistic, we may tentatively conclude that approximation model investigations have some bearing on real data applications.","tags":[],"title":"Attribute fusion in a latent process model for time series of graphs","type":"publication"},{"authors":["Ming Sun","Minh Tang","Carey E. Priebe"],"categories":null,"content":"","date":1358266933,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1358266933,"objectID":"60bad96d264e73d1869edb280ef42b24","permalink":"/publication/gcca_prl/","publishdate":"2013-01-15T12:22:13-04:00","relpermalink":"/publication/gcca_prl/","section":"publication","summary":"Manifold matching works to identify embeddings of multiple disparate data spaces into the same low-dimensional space, where joint inference can be pursued. It is an enabling methodology for fusion and inference from multiple and massive disparate data sources. In this paper we focus on a method called Canonical Correlation Analysis (CCA) and its generalization Generalized Canonical Correlation Analysis (GCCA), which belong to the more general Reduced Rank Regression (RRR) framework. We present an efficiency investigation of CCA and GCCA under different training conditions for a particular text document classification task.","tags":[],"title":"Generalized canonical correlation analysis for disparate data fusion","type":"publication"},{"authors":["Donniell E. Fishkind","Daniel L. Sussman","Minh Tang","Joshua T. Vogelstein","Carey E. Priebe"],"categories":null,"content":"","date":1358266726,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1358266726,"objectID":"d6036a6db14649c19161e33bd2f15edb","permalink":"/publication/fstvp/","publishdate":"2013-01-15T12:18:46-04:00","relpermalink":"/publication/fstvp/","section":"publication","summary":"For random graphs distributed according to a stochastic block model, we consider the inferential task of partitioning vertices into blocks using spectral techniques. Spectral partitioning using the normalized Laplacian and the adjacency matrix have both been shown to be consistent as the number of vertices tend to infinity. Importantly, both procedures require that the number of blocks and the rank of the communication probability matrix be known, even as the rest of the parameters may be unknown. In this paper, we prove that the (suitably modified) adjacency-spectral partitioning procedure, requiring only an upper bound on the rank of the communication probability matrix, is consistent. Indeed, this result demonstrates a robustness to model mis-specification; an overestimate of the rank may impose a moderate performance penalty, but the procedure is still consistent. Furthermore, we extend this procedure to the setting where adjacencies may have multiple modalities and we allow for either directed or undirected graphs.","tags":[],"title":"Consistent adjacency-spectral partitioning for the stochastic block model when the model parameters are unknown","type":"publication"},{"authors":["Daniel L. Sussman","Minh Tang","Donniell E. Fishkind","Carey E. Priebe"],"categories":null,"content":"","date":1349064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1349064000,"objectID":"b81d57584a161138d3f658d92a9df89e","permalink":"/publication/stfp/","publishdate":"2012-10-01T00:00:00-04:00","relpermalink":"/publication/stfp/","section":"publication","summary":"We present a method to estimate block membership of nodes in a random graph generated by a stochastic blockmodel. We use an embedding procedure motivated by the random dot product graph model, a particular example of the latent position model. The embedding associates each node with a vector; these vectors are clustered via minimization of a square error criterion. We prove that this method is consistent for assigning nodes to blocks, as only a negligible number of nodes will be mis-assigned. We prove consistency of the method for directed and undirected graphs. The consistent block assignment makes possible consistent parameter estimation for a stochastic blockmodel. We extend the result in the setting where the number of blocks grows slowly with the number of nodes. Our method is also computationally feasible even for very large graphs. We compare our method to Laplacian spectral clustering through analysis of simulated data and a graph derived from Wikipedia documents.","tags":[],"title":"A consistent adjacency spectral embedding for stochastic blockmodel graphs","type":"publication"}]